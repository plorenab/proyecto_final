{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "921e723c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78c0cafb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_75272/1873662471.py:1: DtypeWarning: Columns (23,26,31) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df2 = pd.read_csv('../data/Raw/Raw_experiments_species.csv')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12798, 124)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv('../data/Raw/Raw_experiments_species.csv')\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa38f8a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LISTA COMPLETA DE VARIABLES\n",
      " 1. Source\n",
      " 2. DOI\n",
      " 3. Authors\n",
      " 4. Year\n",
      " 5. Technical \"Red Criteria\"\n",
      " 6. Risk Assessment \"Red Criteria\"\n",
      " 7. Species\n",
      " 8. Organism Group\n",
      " 9. Environment\n",
      "10. Life Stage\n",
      "11. In vitro/in vivo\n",
      "12. Sex\n",
      "13. Estimated Body Length (cm)\n",
      "14. Estimated Maximum Ingestible Size (mm)\n",
      "15. Experiment Type\n",
      "16. Exposure Route\n",
      "17. Particle Mix?\n",
      "18. Negative Control\n",
      "19. Reference Particle\n",
      "20. Exposure Media\n",
      "21. Solvent\n",
      "22. Detergent\n",
      "23. pH\n",
      "24. Salinity (ppt)\n",
      "25. Temperature (Avg)\n",
      "26. Temperature (Min)\n",
      "27. Temperature (Max)\n",
      "28. Exposure Duration (days)\n",
      "29. Recovery (Days)\n",
      "30. Acute/Chronic\n",
      "31. Number of Doses\n",
      "32. Replicates\n",
      "33. Sample Size\n",
      "34. Dosing Frequency\n",
      "35. Chemicals Added\n",
      "36. Added Chemical Dose (mg/L, nominal)\n",
      "37. Added Chemical Dose (mg/L, measured)\n",
      "38. particles/mL water (master)\n",
      "39. particles/mL water (master), reported or converted\n",
      "40. μg/mL water (master)\n",
      "41. μg/mL water (master), reported or converted\n",
      "42. μm^3/mL water (master)\n",
      "43. μm^2/mL water (master)\n",
      "44. μm^2/ug/mL water (master)\n",
      "45. particles/kg sediment dry weight (master)\n",
      "46. particles/kg sediment dry weight (master), reported or converted\n",
      "47. mg/kg sediment dry weight (master)\n",
      "48. mg/kg sediment dry weight (master), reported or converted\n",
      "49. μm^3/kg sediment dry weight (master)\n",
      "50. μm^2/kg sediment dry weight (master)\n",
      "51. μm^2/ug/kg sediment dry weight (master)\n",
      "52. Nominal Dose Alternative Category\n",
      "53. Nominal Dose Alternative Type\n",
      "54. Nominal Dose Alternative Type Units\n",
      "55. Measured Dose Alternative Category\n",
      "56. Measured Dose Alternative Type\n",
      "57. Measured Dose Alternative Type Units\n",
      "58. Effect\n",
      "59. Direction\n",
      "60. Broad Endpoint Category\n",
      "61. Specific Endpoint Category\n",
      "62. Endpoint\n",
      "63. Level of Biological Organization\n",
      "64. Target Cell or Tissue\n",
      "65. Effect Metric\n",
      "66. AF Time\n",
      "67. AF NOEC\n",
      "68. Polymer\n",
      "69. Shape\n",
      "70. Density (g/cm^3)\n",
      "71. Density, reported or estimated\n",
      "72. Charge\n",
      "73. Zeta Potential (mV)\n",
      "74. Zeta Potential Media\n",
      "75. Functional Group\n",
      "76. Particle Length (μm)\n",
      "77. Particle Width (μm)\n",
      "78. Size Category\n",
      "79. Particle Surface Area (μm^2)\n",
      "80. Particle Volume (μm^3)\n",
      "81. Particle Mass (mg)\n",
      "82. Weathered or Biofouled?\n",
      "83. Size Validated?\n",
      "84. Polymer Validated?\n",
      "85. Shape Validated\n",
      "86. Particle Source\n",
      "87. Sodium Azide Present?\n",
      "88. Screened for Chemical Contamination?\n",
      "89. Particle Cleaning?\n",
      "90. Solvent Rinse\n",
      "91. Background Contamination Monitored?\n",
      "92. Concentration Validated?\n",
      "93. Particle Behavior\n",
      "94. Uptake Validated?\n",
      "95. Uptake Validation Method\n",
      "96. Tissue Distribution\n",
      "97. Organisms Fed?\n",
      "98. Test Medium Score\n",
      "99. Administration Route Score\n",
      "100. Test Species Score\n",
      "101. Sample Size Score\n",
      "102. Control Group Score\n",
      "103. Exposure Duration Score\n",
      "104. Particle Size Score\n",
      "105. Particle Shape Score\n",
      "106. Polymer Type Score\n",
      "107. Source of Microplastics Score\n",
      "108. Data Reporting Score\n",
      "109. Chemical Purity Score\n",
      "110. Laboratory Preparation Score\n",
      "111. Background Contamination Score\n",
      "112. Exposure Verification Score\n",
      "113. Exposure Homogeneity Score\n",
      "114. Exposure Assessment Score\n",
      "115. Replication Score\n",
      "116. Number of Treatments Score\n",
      "117. Endpoints Score\n",
      "118. Food Availability Score\n",
      "119. Effect Thresholds Score\n",
      "120. Dose Response Score\n",
      "121. Concentration Range Score\n",
      "122. Aging and Biofouling Score\n",
      "123. Microplastic Diversity Score\n",
      "124. Exposure Time Score\n"
     ]
    }
   ],
   "source": [
    "print(\"LISTA COMPLETA DE VARIABLES\")\n",
    "for i, columna in enumerate(df2.columns):\n",
    "    print(f\"{i+1:2d}. {columna}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60d838fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Columnas duplicadas\n",
    "duplicadas = df2.columns[df2.T.duplicated()]\n",
    "duplicadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a47ba78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(533)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b89bde8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12265, 124)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df2.drop_duplicates().reset_index(drop=True)\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73d9be2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas a eliminar (37 encontradas):\n",
      " - Measured Dose Alternative Category\n",
      " - Measured Dose Alternative Type\n",
      " - Measured Dose Alternative Type Units\n",
      " - Nominal Dose Alternative Category\n",
      " - Nominal Dose Alternative Type\n",
      " - Nominal Dose Alternative Type Units\n",
      " - Test Medium Score\n",
      " - Administration Route Score\n",
      " - Test Species Score\n",
      " - Sample Size Score\n",
      " - Control Group Score\n",
      " - Exposure Duration Score\n",
      " - Particle Size Score\n",
      " - Particle Shape Score\n",
      " - Polymer Type Score\n",
      " - Source of Microplastics Score\n",
      " - Data Reporting Score\n",
      " - Chemical Purity Score\n",
      " - Laboratory Preparation Score\n",
      " - Background Contamination Score\n",
      " - Exposure Verification Score\n",
      " - Exposure Homogeneity Score\n",
      " - Exposure Assessment Score\n",
      " - Replication Score\n",
      " - Number of Treatments Score\n",
      " - Endpoints Score\n",
      " - Food Availability Score\n",
      " - Effect Thresholds Score\n",
      " - Dose Response Score\n",
      " - Concentration Range Score\n",
      " - Aging and Biofouling Score\n",
      " - Microplastic Diversity Score\n",
      " - Exposure Time Score\n",
      " - pH\n",
      " - Salinity (ppt)\n",
      " - Temperature (Min)\n",
      " - Temperature (Max)\n",
      "\n",
      "✔ Eliminación completada.\n",
      "Nuevo shape: (12265, 87)\n"
     ]
    }
   ],
   "source": [
    "# ELIMINACIÓN DE COLUMNAS INÚTILES / INCOMPLETAS\n",
    "\n",
    "cols_to_drop = [\n",
    "\n",
    "    # Measured / Nominal Dose Alternative (100% NA)\n",
    "    \"Measured Dose Alternative Category\",\n",
    "    \"Measured Dose Alternative Type\",\n",
    "    \"Measured Dose Alternative Type Units\",\n",
    "    \"Nominal Dose Alternative Category\",\n",
    "    \"Nominal Dose Alternative Type\",\n",
    "    \"Nominal Dose Alternative Type Units\",\n",
    "\n",
    "    # Scores metodológicos (30 columnas)\n",
    "    \"Test Medium Score\",\n",
    "    \"Administration Route Score\",\n",
    "    \"Test Species Score\",\n",
    "    \"Sample Size Score\",\n",
    "    \"Control Group Score\",\n",
    "    \"Exposure Duration Score\",\n",
    "    \"Particle Size Score\",\n",
    "    \"Particle Shape Score\",\n",
    "    \"Polymer Type Score\",\n",
    "    \"Source of Microplastics Score\",\n",
    "    \"Data Reporting Score\",\n",
    "    \"Chemical Purity Score\",\n",
    "    \"Laboratory Preparation Score\",\n",
    "    \"Background Contamination Score\",\n",
    "    \"Exposure Verification Score\",\n",
    "    \"Exposure Homogeneity Score\",\n",
    "    \"Exposure Assessment Score\",\n",
    "    \"Replication Score\",\n",
    "    \"Number of Treatments Score\",\n",
    "    \"Endpoints Score\",\n",
    "    \"Food Availability Score\",\n",
    "    \"Effect Thresholds Score\",\n",
    "    \"Dose Response Score\",\n",
    "    \"Concentration Range Score\",\n",
    "    \"Aging and Biofouling Score\",\n",
    "    \"Microplastic Diversity Score\",\n",
    "    \"Exposure Time Score\",\n",
    "\n",
    "    # Variables ambientales eliminadas igual que en humanos\n",
    "    \"pH\",\n",
    "    \"Salinity (ppt)\",\n",
    "    \"Temperature (Min)\",\n",
    "    \"Temperature (Max)\",\n",
    "]\n",
    "\n",
    "\n",
    "cols_to_drop_existing = [c for c in cols_to_drop if c in df2.columns]\n",
    "\n",
    "print(f\"Columnas a eliminar ({len(cols_to_drop_existing)} encontradas):\")\n",
    "for c in cols_to_drop_existing:\n",
    "    print(\" -\", c)\n",
    "\n",
    "# Aplicar eliminación\n",
    "df2 = df2.drop(columns=cols_to_drop_existing)\n",
    "\n",
    "print(\"\\n✔ Eliminación completada.\")\n",
    "print(\"Nuevo shape:\", df2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ea7f9e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Recovery (Days)                                                     97.342030\n",
       "Added Chemical Dose (mg/L, measured)                                96.877293\n",
       "Functional Group                                                    93.689360\n",
       "μm^2/ug/kg sediment dry weight (master)                             92.710966\n",
       "μm^2/kg sediment dry weight (master)                                91.178149\n",
       "μm^3/kg sediment dry weight (master)                                91.178149\n",
       "particles/kg sediment dry weight (master), reported or converted    91.178149\n",
       "particles/kg sediment dry weight (master)                           91.178149\n",
       "mg/kg sediment dry weight (master), reported or converted           90.183449\n",
       "mg/kg sediment dry weight (master)                                  90.183449\n",
       "Charge                                                              87.346107\n",
       "Zeta Potential Media                                                86.946596\n",
       "Zeta Potential (mV)                                                 84.932735\n",
       "Effect Metric                                                       83.848349\n",
       "AF NOEC                                                             66.530779\n",
       "Tissue Distribution                                                 49.270281\n",
       "Uptake Validation Method                                            46.220954\n",
       "Particle Width (μm)                                                 37.431716\n",
       "μm^2/ug/mL water (master)                                           33.118630\n",
       "μm^2/mL water (master)                                              32.719119\n",
       "μm^3/mL water (master)                                              32.719119\n",
       "particles/mL water (master)                                         32.026091\n",
       "particles/mL water (master), reported or converted                  32.026091\n",
       "μg/mL water (master)                                                25.894823\n",
       "μg/mL water (master), reported or converted                         25.894823\n",
       "Estimated Maximum Ingestible Size (mm)                              25.584998\n",
       "Estimated Body Length (cm)                                          25.584998\n",
       "Particle Mass (mg)                                                  19.453730\n",
       "Particle Volume (μm^3)                                              15.197717\n",
       "Particle Surface Area (μm^2)                                        15.197717\n",
       "Density, reported or estimated                                      11.308602\n",
       "Sample Size                                                          6.710151\n",
       "Particle Length (μm)                                                 3.408072\n",
       "Density (g/cm^3)                                                     3.098247\n",
       "Dosing Frequency                                                     2.030167\n",
       "Size Validated?                                                      1.875255\n",
       "Shape Validated                                                      1.875255\n",
       "Effect                                                               1.222992\n",
       "Uptake Validated?                                                    0.774562\n",
       "Species                                                              0.684876\n",
       "Concentration Validated?                                             0.358744\n",
       "Exposure Duration (days)                                             0.122299\n",
       "Size Category                                                        0.097839\n",
       "Replicates                                                           0.008153\n",
       "DOI                                                                  0.000000\n",
       "Year                                                                 0.000000\n",
       "Authors                                                              0.000000\n",
       "Source                                                               0.000000\n",
       "Sex                                                                  0.000000\n",
       "Life Stage                                                           0.000000\n",
       "In vitro/in vivo                                                     0.000000\n",
       "Environment                                                          0.000000\n",
       "Organism Group                                                       0.000000\n",
       "Technical \"Red Criteria\"                                             0.000000\n",
       "Risk Assessment \"Red Criteria\"                                       0.000000\n",
       "Temperature (Avg)                                                    0.000000\n",
       "Detergent                                                            0.000000\n",
       "Solvent                                                              0.000000\n",
       "Exposure Media                                                       0.000000\n",
       "Reference Particle                                                   0.000000\n",
       "Negative Control                                                     0.000000\n",
       "Particle Mix?                                                        0.000000\n",
       "Exposure Route                                                       0.000000\n",
       "Experiment Type                                                      0.000000\n",
       "Number of Doses                                                      0.000000\n",
       "Chemicals Added                                                      0.000000\n",
       "Specific Endpoint Category                                           0.000000\n",
       "Direction                                                            0.000000\n",
       "Broad Endpoint Category                                              0.000000\n",
       "Acute/Chronic                                                        0.000000\n",
       "Added Chemical Dose (mg/L, nominal)                                  0.000000\n",
       "Target Cell or Tissue                                                0.000000\n",
       "Level of Biological Organization                                     0.000000\n",
       "Endpoint                                                             0.000000\n",
       "Polymer                                                              0.000000\n",
       "AF Time                                                              0.000000\n",
       "Shape                                                                0.000000\n",
       "Weathered or Biofouled?                                              0.000000\n",
       "Polymer Validated?                                                   0.000000\n",
       "Particle Cleaning?                                                   0.000000\n",
       "Screened for Chemical Contamination?                                 0.000000\n",
       "Sodium Azide Present?                                                0.000000\n",
       "Particle Source                                                      0.000000\n",
       "Particle Behavior                                                    0.000000\n",
       "Background Contamination Monitored?                                  0.000000\n",
       "Solvent Rinse                                                        0.000000\n",
       "Organisms Fed?                                                       0.000000\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#nulos\n",
    "with pd.option_context('display.max_rows', None):\n",
    "    display(df2.isna().mean().sort_values(ascending=False) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be34d6f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas eliminadas:\n",
      "✔ Recovery (Days)\n",
      "✔ Added Chemical Dose (mg/L, measured)\n",
      "✔ Functional Group\n",
      "✔ μm^2/ug/kg sediment dry weight (master)\n",
      "✔ μm^2/kg sediment dry weight (master)\n",
      "✔ μm^3/kg sediment dry weight (master)\n",
      "✔ particles/kg sediment dry weight (master), reported or converted\n",
      "✔ particles/kg sediment dry weight (master)\n",
      "✔ mg/kg sediment dry weight (master), reported or converted\n",
      "✔ mg/kg sediment dry weight (master)\n",
      "\n",
      "Total eliminadas: 10\n",
      "Shape actual: (12265, 77)\n"
     ]
    }
   ],
   "source": [
    "# ELIMINACIÓN DE COLUMNAS IRRELEVANTES CON >90% NA\n",
    "\n",
    "cols_to_drop = [\n",
    "    \"Recovery (Days)\",\n",
    "    \"Added Chemical Dose (mg/L, measured)\",\n",
    "    \"Functional Group\",   # en este dataset tiene 94% NA → se elimina aquí\n",
    "    \"μm^2/ug/kg sediment dry weight (master)\",\n",
    "    \"μm^2/kg sediment dry weight (master)\",\n",
    "    \"μm^3/kg sediment dry weight (master)\",\n",
    "    \"particles/kg sediment dry weight (master), reported or converted\",\n",
    "    \"particles/kg sediment dry weight (master)\",\n",
    "    \"mg/kg sediment dry weight (master), reported or converted\",\n",
    "    \"mg/kg sediment dry weight (master)\"\n",
    "]\n",
    "\n",
    "# Filtrar solo las que realmente existen en df (seguridad)\n",
    "cols_existing = [c for c in cols_to_drop if c in df2.columns]\n",
    "\n",
    "df2.drop(columns=cols_existing, inplace=True)\n",
    "\n",
    "print(\"Columnas eliminadas:\")\n",
    "for c in cols_existing:\n",
    "    print(\"✔\", c)\n",
    "\n",
    "print(f\"\\nTotal eliminadas: {len(cols_existing)}\")\n",
    "print(f\"Shape actual: {df2.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b756c12a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Charge                                                87.346107\n",
       "Zeta Potential Media                                  86.946596\n",
       "Zeta Potential (mV)                                   84.932735\n",
       "Effect Metric                                         83.848349\n",
       "AF NOEC                                               66.530779\n",
       "Tissue Distribution                                   49.270281\n",
       "Uptake Validation Method                              46.220954\n",
       "Particle Width (μm)                                   37.431716\n",
       "μm^2/ug/mL water (master)                             33.118630\n",
       "μm^3/mL water (master)                                32.719119\n",
       "μm^2/mL water (master)                                32.719119\n",
       "particles/mL water (master), reported or converted    32.026091\n",
       "particles/mL water (master)                           32.026091\n",
       "μg/mL water (master)                                  25.894823\n",
       "μg/mL water (master), reported or converted           25.894823\n",
       "Estimated Body Length (cm)                            25.584998\n",
       "Estimated Maximum Ingestible Size (mm)                25.584998\n",
       "Particle Mass (mg)                                    19.453730\n",
       "Particle Volume (μm^3)                                15.197717\n",
       "Particle Surface Area (μm^2)                          15.197717\n",
       "Density, reported or estimated                        11.308602\n",
       "Sample Size                                            6.710151\n",
       "Particle Length (μm)                                   3.408072\n",
       "Density (g/cm^3)                                       3.098247\n",
       "Dosing Frequency                                       2.030167\n",
       "Size Validated?                                        1.875255\n",
       "Shape Validated                                        1.875255\n",
       "Effect                                                 1.222992\n",
       "Uptake Validated?                                      0.774562\n",
       "Species                                                0.684876\n",
       "Concentration Validated?                               0.358744\n",
       "Exposure Duration (days)                               0.122299\n",
       "Size Category                                          0.097839\n",
       "Replicates                                             0.008153\n",
       "Sex                                                    0.000000\n",
       "Life Stage                                             0.000000\n",
       "In vitro/in vivo                                       0.000000\n",
       "Source                                                 0.000000\n",
       "DOI                                                    0.000000\n",
       "Authors                                                0.000000\n",
       "Environment                                            0.000000\n",
       "Risk Assessment \"Red Criteria\"                         0.000000\n",
       "Organism Group                                         0.000000\n",
       "Year                                                   0.000000\n",
       "Technical \"Red Criteria\"                               0.000000\n",
       "Target Cell or Tissue                                  0.000000\n",
       "Level of Biological Organization                       0.000000\n",
       "Endpoint                                               0.000000\n",
       "Specific Endpoint Category                             0.000000\n",
       "Broad Endpoint Category                                0.000000\n",
       "Direction                                              0.000000\n",
       "Chemicals Added                                        0.000000\n",
       "Added Chemical Dose (mg/L, nominal)                    0.000000\n",
       "Solvent                                                0.000000\n",
       "Exposure Media                                         0.000000\n",
       "Reference Particle                                     0.000000\n",
       "Negative Control                                       0.000000\n",
       "Acute/Chronic                                          0.000000\n",
       "Temperature (Avg)                                      0.000000\n",
       "Detergent                                              0.000000\n",
       "Number of Doses                                        0.000000\n",
       "Particle Mix?                                          0.000000\n",
       "Exposure Route                                         0.000000\n",
       "Experiment Type                                        0.000000\n",
       "Shape                                                  0.000000\n",
       "Polymer                                                0.000000\n",
       "AF Time                                                0.000000\n",
       "Weathered or Biofouled?                                0.000000\n",
       "Polymer Validated?                                     0.000000\n",
       "Particle Cleaning?                                     0.000000\n",
       "Screened for Chemical Contamination?                   0.000000\n",
       "Sodium Azide Present?                                  0.000000\n",
       "Particle Source                                        0.000000\n",
       "Particle Behavior                                      0.000000\n",
       "Background Contamination Monitored?                    0.000000\n",
       "Solvent Rinse                                          0.000000\n",
       "Organisms Fed?                                         0.000000\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#nulos\n",
    "with pd.option_context('display.max_rows', None):\n",
    "    display(df2.isna().mean().sort_values(ascending=False) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18ed3127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.06350460e+15, 8.49273459e+15, 4.65343983e+12, ...,\n",
       "       3.05504946e+14, 3.05504946e+15, 3.05504946e+16], shape=(1169,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['μm^2/ug/mL water (master)'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b239572e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Charge imputado con 'unknown'\n"
     ]
    }
   ],
   "source": [
    "df2[\"charge_missing\"] = df2[\"Charge\"].isna().astype(int)\n",
    "df2[\"Charge\"] = df2[\"Charge\"].fillna(\"unknown\")\n",
    "\n",
    "print(\"✔ Charge imputado con 'unknown'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "036a9f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Zeta Potential Media normalizada e imputada\n",
      "Valores únicos finales: ['not_reported' 'natural_seawater' 'artificial_seawater'\n",
      " 'moderately.hard.water' 'filtered_seawater' 'hbss'\n",
      " 'filtered_autoclaved_natural_seawater' 'sterile.natural.seawater'\n",
      " 'trisacetatephosphatemedium' 'ultrapure_water'\n",
      " 'artificial_seawater_methylene_blue' 'uv.treated.filtered.seawater'\n",
      " 'instant_ocean' 'mq_water_mussel_culture' 'hemolymph serum (mussel)'\n",
      " 'filtered artificial water' 'milliq_water' 'aap medium'\n",
      " 'immune cell exposure media' \"dulbecco's modified eagle's medium\"\n",
      " 'zebrafish water' 'bbm + chorella' 'bbm + subcapita' 'asw']\n"
     ]
    }
   ],
   "source": [
    "# Zeta Potential Media\n",
    "\n",
    "col = \"Zeta Potential Media\"\n",
    "\n",
    "# Pasar a texto, minúsculas, quitar espacios\n",
    "df2[col] = df2[col].astype(str).str.strip().str.lower().replace(\"nan\", np.nan)\n",
    "\n",
    "# Diccionario de normalización\n",
    "zeta_media_map = {\n",
    "    \"milliq water\": \"milliq_water\",\n",
    "    \"milli q\": \"milliq_water\",\n",
    "    \"ultra.pure.water\": \"ultrapure_water\",\n",
    "    \"ultrapure water\": \"ultrapure_water\",\n",
    "\n",
    "    \"natural.seawater\": \"natural_seawater\",\n",
    "    \"natural filtered seawater\": \"natural_seawater\",\n",
    "\n",
    "    \"filtered.seawater\": \"filtered_seawater\",\n",
    "    \"filtered seawater\": \"filtered_seawater\",\n",
    "\n",
    "    \"artificial.seawater\": \"artificial_seawater\",\n",
    "    \"artificial seawater\": \"artificial_seawater\",\n",
    "\n",
    "    \"instant.ocean\": \"instant_ocean\",\n",
    "\n",
    "    \"filtered.autoclaved.natural.seawater\": \"filtered_autoclaved_natural_seawater\",\n",
    "    \"mq water and mussle culture media\": \"mq_water_mussel_culture\",\n",
    "\n",
    "    \"artificial.seawater.00003%methyleneblue\": \"artificial_seawater_methylene_blue\"\n",
    "}\n",
    "\n",
    "# Aplicar normalización parcial\n",
    "df2[col] = df2[col].replace(zeta_media_map)\n",
    "\n",
    "# Crear flag de missing\n",
    "df2[\"zeta_media_missing\"] = df2[col].isna().astype(int)\n",
    "\n",
    "# Reemplazar NaN por not_reported\n",
    "df2[col] = df2[col].fillna(\"not_reported\")\n",
    "\n",
    "print(\"✔ Zeta Potential Media normalizada e imputada\")\n",
    "print(\"Valores únicos finales:\", df2[col].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f46d29d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Imputación Zeta Potential (mV) ===\n",
      "Filas totales: 12265\n",
      "Missing iniciales: 10417\n",
      "Imputadas por mediana de polymer: 8916\n",
      "Imputadas por mediana global: 1501\n",
      "Missing restantes: 0\n",
      "Mediana global usada como fallback: -13.71\n"
     ]
    }
   ],
   "source": [
    "# IMPUTACIÓN: Zeta Potential (mV)\n",
    "\n",
    "col = \"Zeta Potential (mV)\"\n",
    "group = \"Polymer\"\n",
    "\n",
    "# 1. Convertir a numérico\n",
    "df2[col] = pd.to_numeric(df2[col], errors='coerce')\n",
    "\n",
    "# 2. Normalizar Polymer\n",
    "df2[group] = df2[group].astype(str).str.strip()\n",
    "\n",
    "# 3. Flag de missing original\n",
    "df2[\"zeta_missing\"] = df2[col].isna().astype(int)\n",
    "\n",
    "# 4. Mediana por polymer\n",
    "median_by_poly = df2.groupby(group)[col].median()\n",
    "\n",
    "# 5. Columna auxiliar: mediana correspondiente a cada fila\n",
    "df2[\"zeta_median_by_poly\"] = df2[group].map(median_by_poly)\n",
    "\n",
    "# 6. Mediana global (fallback)\n",
    "global_median = df2[col].median()\n",
    "\n",
    "# 7. Imputación final\n",
    "df2[col] = df2[col].fillna(df2[\"zeta_median_by_poly\"])\n",
    "df2[col] = df2[col].fillna(global_median)\n",
    "\n",
    "# 8. Flags de trazabilidad\n",
    "df2[\"zeta_imputed_by_group\"] = (\n",
    "    (df2[\"zeta_missing\"] == 1) & df2[\"zeta_median_by_poly\"].notna()\n",
    ").astype(int)\n",
    "\n",
    "df2[\"zeta_imputed_by_global\"] = (\n",
    "    (df2[\"zeta_missing\"] == 1) & df2[\"zeta_median_by_poly\"].isna()\n",
    ").astype(int)\n",
    "\n",
    "# 9. Limpiar columna auxiliar\n",
    "df2 = df2.drop(columns=[\"zeta_median_by_poly\"])\n",
    "\n",
    "# 10. Resumen\n",
    "print(\"=== Imputación Zeta Potential (mV) ===\")\n",
    "print(\"Filas totales:\", len(df2))\n",
    "print(\"Missing iniciales:\", df2['zeta_missing'].sum())\n",
    "print(\"Imputadas por mediana de polymer:\", df2['zeta_imputed_by_group'].sum())\n",
    "print(\"Imputadas por mediana global:\", df2['zeta_imputed_by_global'].sum())\n",
    "print(\"Missing restantes:\", df2[col].isna().sum())\n",
    "print(\"Mediana global usada como fallback:\", global_median)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48c8af7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Effect Metric imputado con 'not_reported'\n",
      "Valores únicos: ['not_reported' 'NOEC' 'LOEC' 'LC50' 'HONEC' 'EC50' 'IC50' 'EC10' 'EC20'\n",
      " 'LC20']\n"
     ]
    }
   ],
   "source": [
    "col = \"Effect Metric\"\n",
    "\n",
    "# Normalizar a texto\n",
    "df2[col] = df2[col].astype(str).str.strip().replace(\"nan\", np.nan)\n",
    "\n",
    "# Flag de missing original\n",
    "df2[\"effect_metric_missing\"] = df2[col].isna().astype(int)\n",
    "\n",
    "# Imputación con not_reported\n",
    "df2[col] = df2[col].fillna(\"not_reported\")\n",
    "\n",
    "print(\"✔ Effect Metric imputado con 'not_reported'\")\n",
    "print(\"Valores únicos:\", df2[col].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65c3440c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ AF NOEC imputado con 'not_reported'\n",
      "Valores únicos: ['2.0' 'not_reported' '1.0' '10.0']\n"
     ]
    }
   ],
   "source": [
    "col = \"AF NOEC\"\n",
    "\n",
    "# Normalizar la columna a texto\n",
    "df2[col] = df2[col].astype(str).str.strip().replace(\"nan\", np.nan)\n",
    "\n",
    "# Flag de missing original\n",
    "df2[\"af_noec_missing\"] = df2[col].isna().astype(int)\n",
    "\n",
    "# Imputación con 'not_reported'\n",
    "df2[col] = df2[col].fillna(\"not_reported\")\n",
    "\n",
    "print(\"✔ AF NOEC imputado con 'not_reported'\")\n",
    "print(\"Valores únicos:\", df2[col].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "856f8ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Tissue Distribution eliminada\n"
     ]
    }
   ],
   "source": [
    "# En los otros dos datasets se ha eliminado por: \n",
    "# No existe forma razonable de unificar más de 40 tejidos diferentes\n",
    "# No es una variable primaria para predecir toxicidad\n",
    "df2 = df2.drop(columns=[\"Tissue Distribution\"])\n",
    "print(\"✔ Tissue Distribution eliminada\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e6caf3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Uptake Validation Method eliminada\n"
     ]
    }
   ],
   "source": [
    "# Se elimina porque no existe en los otros datasets\n",
    "df2 = df2.drop(columns=[\"Uptake Validation Method\"])\n",
    "print(\"✔ Uptake Validation Method eliminada\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba409834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Particle Width imputado correctamente\n",
      "Missing tras imputación: 0\n"
     ]
    }
   ],
   "source": [
    "# Imputación Particle Width (μm)\n",
    "\n",
    "col = \"Particle Width (μm)\"\n",
    "group_col = \"Shape\"\n",
    "\n",
    "# 1. Asegurar numérico\n",
    "df2[col] = pd.to_numeric(df2[col], errors=\"coerce\")\n",
    "\n",
    "# 2. Normalizar Shape\n",
    "df2[group_col] = df2[group_col].astype(str).str.strip().replace({\"nan\": np.nan})\n",
    "\n",
    "# 3. Flag de missing original\n",
    "df2[\"particle_width_missing\"] = df2[col].isna().astype(int)\n",
    "\n",
    "# 4. Mediana global\n",
    "median_global = df2[col].median()\n",
    "\n",
    "# 5. Mediana por shape\n",
    "median_by_shape = df2.groupby(group_col)[col].median()\n",
    "\n",
    "# 6. Crear función de imputación\n",
    "def impute_width(row):\n",
    "    if pd.notna(row[col]):\n",
    "        return row[col]\n",
    "    shape = row[group_col]\n",
    "    if pd.notna(shape) and pd.notna(median_by_shape.get(shape, np.nan)):\n",
    "        return median_by_shape[shape]\n",
    "    return median_global\n",
    "\n",
    "# 7. Aplicar imputación\n",
    "df2[col] = df2.apply(impute_width, axis=1)\n",
    "\n",
    "# 8. Confirmación\n",
    "print(\"✔ Particle Width imputado correctamente\")\n",
    "print(\"Missing tras imputación:\", df2[col].isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82fbb9b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas eliminadas: ['μm^2/ug/mL water (master)', 'μm^3/mL water (master)', 'μm^2/mL water (master)']\n"
     ]
    }
   ],
   "source": [
    "cols_to_drop_master = [\n",
    "    \"μm^2/ug/mL water (master)\",\n",
    "    \"μm^3/mL water (master)\",\n",
    "    \"μm^2/mL water (master)\"\n",
    "]\n",
    "\n",
    "# Filtrar solo las que realmente existen\n",
    "cols_to_drop_master = [c for c in cols_to_drop_master if c in df2.columns]\n",
    "\n",
    "df2 = df2.drop(columns=cols_to_drop_master)\n",
    "\n",
    "print(\"Columnas eliminadas:\", cols_to_drop_master)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ddb92a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas eliminadas (‘reported or converted’):\n",
      " - particles/mL water (master), reported or converted\n",
      " - μg/mL water (master), reported or converted\n",
      "\n",
      "Total eliminadas: 2\n"
     ]
    }
   ],
   "source": [
    "# ELIMINAR TODAS LAS COLUMNAS \"reported or converted\"\n",
    "\n",
    "cols_reported = [c for c in df2.columns if \"reported or converted\" in c.lower()]\n",
    "\n",
    "df2 = df2.drop(columns=cols_reported)\n",
    "\n",
    "print(\"Columnas eliminadas (‘reported or converted’):\")\n",
    "for c in cols_reported:\n",
    "    print(\" -\", c)\n",
    "\n",
    "print(\"\\nTotal eliminadas:\", len(cols_reported))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9b98d510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ particles/mL water (master) tratado correctamente\n",
      "NAs: 3928\n"
     ]
    }
   ],
   "source": [
    "col = \"particles/mL water (master)\"\n",
    "\n",
    "# Convertir a numérico\n",
    "df2[col] = pd.to_numeric(df2[col], errors=\"coerce\")\n",
    "\n",
    "# Crear flag de missing\n",
    "df2[\"particles_ml_missing\"] = df2[col].isna().astype(int)\n",
    "\n",
    "print(\"✔ particles/mL water (master) tratado correctamente\")\n",
    "print(\"NAs:\", df2[col].isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cd2b1715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Flag creado para μg/mL water (master)\n",
      "NAs: 3176\n",
      "Valores únicos (sin NA): [np.float64(0.00139), np.float64(0.005993938), np.float64(0.0111), np.float64(0.059939378), np.float64(0.599393782), np.float64(2.996968912), np.float64(5.993937824), np.float64(11.98787565), np.float64(27.57211399), np.float64(59.93937824)] ...\n"
     ]
    }
   ],
   "source": [
    "col = \"μg/mL water (master)\"\n",
    "\n",
    "# Convertir a numérico\n",
    "df2[col] = pd.to_numeric(df2[col], errors=\"coerce\")\n",
    "\n",
    "# Crear flag de missing\n",
    "df2[\"ug_ml_water_missing\"] = df2[col].isna().astype(int)\n",
    "\n",
    "print(\"✔ Flag creado para μg/mL water (master)\")\n",
    "print(\"NAs:\", df2[col].isna().sum())\n",
    "print(\"Valores únicos (sin NA):\", sorted(df2[col].dropna().unique()[:10]), \"...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "588fcf71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Imputación Estimated Body Length (cm) ===\n",
      "Missing original: 3138\n",
      "Mediana global usada como fallback: 4.0\n",
      "Missing tras imputación: 0\n",
      "Valores únicos (primeros 20): [5.00e-01 8.00e-02 7.80e-01 1.50e+01 9.00e-02 4.00e+00 8.50e-01 1.20e+00\n",
      " 1.00e+00 1.10e+01 2.50e+00 2.49e-02 3.00e+00 3.50e-01 1.40e+01 3.00e-01\n",
      " 9.00e+00 9.00e-03 3.50e+01 9.80e+00]\n"
     ]
    }
   ],
   "source": [
    "# Imputación Estimated Body Length (cm)\n",
    "\n",
    "col = \"Estimated Body Length (cm)\"\n",
    "group = \"Species\"\n",
    "\n",
    "# Convertir a numérico correctamente\n",
    "df2[col] = pd.to_numeric(df2[col], errors=\"coerce\")\n",
    "\n",
    "# Flag de missing original\n",
    "df2[\"estimated_body_length_missing\"] = df2[col].isna().astype(int)\n",
    "\n",
    "# Calcular mediana por Species\n",
    "median_by_species = df2.groupby(group)[col].median()\n",
    "\n",
    "# Imputar por mediana de la especie\n",
    "mask_missing = df2[col].isna()\n",
    "df2.loc[mask_missing, col] = df2.loc[mask_missing, group].map(median_by_species)\n",
    "\n",
    "# Fallback global por si quedan NA\n",
    "global_median = df2[col].median(skipna=True)\n",
    "df2[col] = df2[col].fillna(global_median)\n",
    "\n",
    "# Resumen\n",
    "print(\"=== Imputación Estimated Body Length (cm) ===\")\n",
    "print(\"Missing original:\", df2['estimated_body_length_missing'].sum())\n",
    "print(\"Mediana global usada como fallback:\", global_median)\n",
    "print(\"Missing tras imputación:\", df2[col].isna().sum())\n",
    "print(\"Valores únicos (primeros 20):\", df2[col].unique()[:20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d0224ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Imputación Estimated Maximum Ingestible Size (mm) ===\n",
      "Missing originales: 3138\n",
      "Mediana global usada en fallback: 2.3794919391134903\n",
      "Missing tras imputación: 0\n",
      "Valores únicos (primeros 20): [3.41120548e-01 6.15852001e-02 5.16779846e-01 8.17874834e+00\n",
      " 6.87476612e-02 2.37949194e+00 5.59977037e-01 7.72793040e-01\n",
      " 6.51778454e-01 6.12159942e+00 1.53396610e+00 2.07009278e-02\n",
      " 1.81877495e+00 2.44463463e-01 7.66828416e+00 2.11679579e-01\n",
      " 5.07525571e+00 8.00125162e-03 1.80473716e+01 5.49546286e+00]\n"
     ]
    }
   ],
   "source": [
    "# Imputación Estimated Maximum Ingestible Size (mm)\n",
    "\n",
    "col = \"Estimated Maximum Ingestible Size (mm)\"\n",
    "group = \"Species\"\n",
    "\n",
    "# Convertir a numérico\n",
    "df2[col] = pd.to_numeric(df2[col], errors=\"coerce\")\n",
    "\n",
    "# Flag de missing original\n",
    "df2[\"estimated_max_ingestible_missing\"] = df2[col].isna().astype(int)\n",
    "\n",
    "# Mediana por Species\n",
    "median_by_species = df2.groupby(group)[col].median()\n",
    "\n",
    "# Imputación por especie\n",
    "mask_missing = df2[col].isna()\n",
    "df2.loc[mask_missing, col] = df2.loc[mask_missing, group].map(median_by_species)\n",
    "\n",
    "# Fallback global\n",
    "global_median = df2[col].median(skipna=True)\n",
    "df2[col] = df2[col].fillna(global_median)\n",
    "\n",
    "# Resumen\n",
    "print(\"=== Imputación Estimated Maximum Ingestible Size (mm) ===\")\n",
    "print(\"Missing originales:\", df2[\"estimated_max_ingestible_missing\"].sum())\n",
    "print(\"Mediana global usada en fallback:\", global_median)\n",
    "print(\"Missing tras imputación:\", df2[col].isna().sum())\n",
    "print(\"Valores únicos (primeros 20):\", df2[col].unique()[:20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b154f9c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Imputación Particle Mass (mg) ===\n",
      "Total filas: 12265\n",
      "Missing originales: 2386\n",
      "Imputadas por mediana Polymer: 1804\n",
      "Imputadas por mediana Global: 582\n",
      "Missing tras imputación: 0\n",
      "Mediana global: 2.225556648040447e-07\n"
     ]
    }
   ],
   "source": [
    "# Imputación Particle Mass (mg) — mediana por Polymer \n",
    "\n",
    "col2 = \"Particle Mass (mg)\"\n",
    "group_col2 = \"Polymer\"\n",
    "\n",
    "# Convertir a numérico\n",
    "df2[col2] = pd.to_numeric(df2[col2], errors=\"coerce\")\n",
    "\n",
    "# Normalizar Polymer (importante!)\n",
    "df2[group_col2] = df2[group_col2].astype(str).str.strip()\n",
    "\n",
    "# Flag de missing original\n",
    "df2[\"particle_mass_missing\"] = df2[col2].isna().astype(int)\n",
    "\n",
    "# Medianas por polymer\n",
    "medians_by_poly = df2.groupby(group_col2)[col2].median()\n",
    "\n",
    "# Crear columna auxiliar con la mediana asignada a cada fila\n",
    "df2[\"mass_median_by_poly\"] = df2[group_col2].map(medians_by_poly)\n",
    "\n",
    "# Mediana global\n",
    "global_median = df2[col2].median()\n",
    "\n",
    "# Imputación final\n",
    "df2[col2] = df2[col2].fillna(df2[\"mass_median_by_poly\"])\n",
    "df2[col2] = df2[col2].fillna(global_median)\n",
    "\n",
    "# Flags de imputación\n",
    "df2[\"particle_mass_imputed_by_group\"] = (\n",
    "    (df2[\"particle_mass_missing\"] == 1) & df2[\"mass_median_by_poly\"].notna()\n",
    ").astype(int)\n",
    "\n",
    "df2[\"particle_mass_imputed_by_global\"] = (\n",
    "    (df2[\"particle_mass_missing\"] == 1) & df2[\"mass_median_by_poly\"].isna()\n",
    ").astype(int)\n",
    "\n",
    "# Limpiar auxiliar\n",
    "df2 = df2.drop(columns=[\"mass_median_by_poly\"])\n",
    "\n",
    "# Resumen\n",
    "print(\"=== Imputación Particle Mass (mg) ===\")\n",
    "print(\"Total filas:\", len(df2))\n",
    "print(\"Missing originales:\", df2[\"particle_mass_missing\"].sum())\n",
    "print(\"Imputadas por mediana Polymer:\", df2[\"particle_mass_imputed_by_group\"].sum())\n",
    "print(\"Imputadas por mediana Global:\", df2[\"particle_mass_imputed_by_global\"].sum())\n",
    "print(\"Missing tras imputación:\", df2[col2].isna().sum())\n",
    "print(\"Mediana global:\", global_median)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "599d3879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Imputación Particle Volume (μm³) ===\n",
      "Missing originales: 1864\n",
      "Missing tras imputación: 0\n",
      "Mediana global usada: 207.995948414995\n"
     ]
    }
   ],
   "source": [
    "# Imputación Particle Volume (μm³) — mediana por Size Category\n",
    "\n",
    "vol_col = \"Particle Volume (μm^3)\"\n",
    "group_col = \"Size Category\"\n",
    "\n",
    "# normalizar categoría\n",
    "df2[group_col] = df2[group_col].astype(str).str.strip()\n",
    "df2[group_col] = df2[group_col].replace({\"nan\": np.nan})\n",
    "\n",
    "# convertir volumen a numérico\n",
    "df2[vol_col] = pd.to_numeric(df2[vol_col], errors=\"coerce\")\n",
    "\n",
    "# flag missing original\n",
    "df2[\"particle_volume_missing\"] = df2[vol_col].isna().astype(int)\n",
    "\n",
    "# medianas por Size Category\n",
    "medians_by_size = df2.groupby(group_col)[vol_col].median()\n",
    "\n",
    "# asignar mediana según categoría\n",
    "df2[\"vol_median_by_size\"] = df2[group_col].map(medians_by_size)\n",
    "\n",
    "# fallback global\n",
    "global_median = df2[vol_col].median()\n",
    "\n",
    "# imputación final\n",
    "df2[vol_col] = df2[vol_col].fillna(df2[\"vol_median_by_size\"])\n",
    "df2[vol_col] = df2[vol_col].fillna(global_median)\n",
    "\n",
    "# limpiar auxiliar\n",
    "df2 = df2.drop(columns=[\"vol_median_by_size\"])\n",
    "\n",
    "# resumen\n",
    "print(\"=== Imputación Particle Volume (μm³) ===\")\n",
    "print(\"Missing originales:\", df2[\"particle_volume_missing\"].sum())\n",
    "print(\"Missing tras imputación:\", df2[vol_col].isna().sum())\n",
    "print(\"Mediana global usada:\", global_median)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c53f9719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Imputación Particle Surface Area (μm²) ===\n",
      "Missing originales: 1864\n",
      "Missing tras imputación: 0\n",
      "Mediana global usada: 189.43354210258192\n"
     ]
    }
   ],
   "source": [
    "# Imputación Particle Surface Area (μm²) — mediana por Size Category\n",
    "\n",
    "area_col = \"Particle Surface Area (μm^2)\"\n",
    "group_col = \"Size Category\"\n",
    "\n",
    "# Normalizar categoría\n",
    "df2[group_col] = df2[group_col].astype(str).str.strip()\n",
    "df2[group_col] = df2[group_col].replace({\"nan\": np.nan})\n",
    "\n",
    "# Convertir a numérico\n",
    "df2[area_col] = pd.to_numeric(df2[area_col], errors=\"coerce\")\n",
    "\n",
    "# Flag missing original\n",
    "df2[\"particle_area_missing\"] = df2[area_col].isna().astype(int)\n",
    "\n",
    "# Medianas por size category\n",
    "medians_by_size = df2.groupby(group_col)[area_col].median()\n",
    "\n",
    "# Map a cada fila\n",
    "df2[\"area_median_by_size\"] = df2[group_col].map(medians_by_size)\n",
    "\n",
    "# Mediana global\n",
    "global_median = df2[area_col].median()\n",
    "\n",
    "# Imputación en cascada\n",
    "df2[area_col] = df2[area_col].fillna(df2[\"area_median_by_size\"])\n",
    "df2[area_col] = df2[area_col].fillna(global_median)\n",
    "\n",
    "# Borrar auxiliar\n",
    "df2 = df2.drop(columns=[\"area_median_by_size\"])\n",
    "\n",
    "print(\"=== Imputación Particle Surface Area (μm²) ===\")\n",
    "print(\"Missing originales:\", df2[\"particle_area_missing\"].sum())\n",
    "print(\"Missing tras imputación:\", df2[area_col].isna().sum())\n",
    "print(\"Mediana global usada:\", global_median)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9de75c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Density, reported or estimated\n",
      "estimated    8595\n",
      "reported     3290\n",
      "unknown       380\n",
      "Name: count, dtype: int64\n",
      "density_reported_flag     3290\n",
      "density_estimated_flag    8595\n",
      "density_unknown_flag       380\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "col_cat = 'Density, reported or estimated'\n",
    "col_num = 'Density (g/cm^3)'\n",
    "\n",
    "# Normalizar a string y pasar a minúsculas\n",
    "df2[col_cat] = df2[col_cat].astype(str).str.strip().str.lower().replace({'nan': np.nan})\n",
    "\n",
    "# Normalizar variantes (por si aparecen en el futuro)\n",
    "df2[col_cat] = df2[col_cat].replace({\n",
    "    'est': 'estimated',\n",
    "    'estim': 'estimated',\n",
    "    'rep': 'reported',\n",
    "    'rpt': 'reported'\n",
    "})\n",
    "\n",
    "# Inferir reported si hay dato numérico pero falta categoría\n",
    "mask_infer_reported = df2[col_cat].isna() & df2[col_num].notna()\n",
    "df2.loc[mask_infer_reported, col_cat] = 'reported'\n",
    "\n",
    "# Rellenar el resto con unknown\n",
    "df2[col_cat] = df2[col_cat].fillna('unknown')\n",
    "\n",
    "# Crear flags\n",
    "df2['density_reported_flag']  = (df2[col_cat] == 'reported').astype(int)\n",
    "df2['density_estimated_flag'] = (df2[col_cat] == 'estimated').astype(int)\n",
    "df2['density_unknown_flag']   = (df2[col_cat] == 'unknown').astype(int)\n",
    "\n",
    "# Convertir a categoría\n",
    "df2[col_cat] = df2[col_cat].astype('category')\n",
    "\n",
    "# Comprobación\n",
    "print(df2[col_cat].value_counts(dropna=False))\n",
    "print(df2[['density_reported_flag',\n",
    "          'density_estimated_flag',\n",
    "          'density_unknown_flag']].sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3856ef89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mediana global usada como fallback: 5.0\n",
      "Missing finales: 0\n",
      "Outliers detectados (>100): 640\n",
      "Ejemplo de valores finales: [ 1. 10.  5.  2.  3. 15.  8.  4.  9. 20.  6. 18. 17. 23. 24. 12. 50. 14.\n",
      " 16. 68.]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "col = 'Sample Size'\n",
    "group_col = 'Experiment Type'\n",
    "\n",
    "# --- Copia de seguridad ---\n",
    "if 'Sample Size_original' not in df2.columns:\n",
    "    df2['Sample Size_original'] = df2[col]\n",
    "\n",
    "# --- Función para extraer el primer número de un string ---\n",
    "def extract_first_number(x):\n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    s = str(x).strip()\n",
    "    s = s.replace(\",\", \"\")  # quitar millares\n",
    "    m = re.search(r'[-+]?\\d*\\.?\\d+', s)\n",
    "    if m:\n",
    "        try:\n",
    "            return float(m.group(0))\n",
    "        except:\n",
    "            return np.nan\n",
    "    return np.nan\n",
    "\n",
    "# --- Extraer número ---\n",
    "df2['Sample Size_num'] = df2['Sample Size_original'].apply(extract_first_number)\n",
    "\n",
    "# --- Flag de missing original ---\n",
    "df2['sample_size_missing'] = df2['Sample Size_num'].isna().astype(int)\n",
    "\n",
    "# --- Detectar outliers (>100) ---\n",
    "df2['sample_size_outlier'] = (df2['Sample Size_num'] > 100).astype(int)\n",
    "\n",
    "# Reemplazar outliers por NaN para imputación correcta\n",
    "df2.loc[df2['Sample Size_num'] > 100, 'Sample Size_num'] = np.nan\n",
    "\n",
    "# --- Imputación por mediana de Experiment Type ---\n",
    "df2['Sample Size_num'] = df2.groupby(group_col)['Sample Size_num'] \\\n",
    "                            .transform(lambda x: x.fillna(x.median()))\n",
    "\n",
    "# --- Fallback global ---\n",
    "global_median = df2['Sample Size_num'].median()\n",
    "df2['Sample Size_num'] = df2['Sample Size_num'].fillna(global_median)\n",
    "\n",
    "# Convertir a entero si todos los valores son enteros\n",
    "if df2['Sample Size_num'].dropna().apply(float.is_integer).all():\n",
    "    df2['Sample Size_num'] = df2['Sample Size_num'].astype('Int64')\n",
    "\n",
    "# Reemplazar columna original\n",
    "df2['Sample Size'] = df2['Sample Size_num']\n",
    "\n",
    "print(\"Mediana global usada como fallback:\", global_median)\n",
    "print(\"Missing finales:\", df2['Sample Size'].isna().sum())\n",
    "print(\"Outliers detectados (>100):\", df2['sample_size_outlier'].sum())\n",
    "print(\"Ejemplo de valores finales:\", df2['Sample Size'].unique()[:20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "98319f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Eliminada columna auxiliar Sample Size_original\n"
     ]
    }
   ],
   "source": [
    "df2 = df2.drop(columns=[\"Sample Size_original\"])\n",
    "print(\"✔ Eliminada columna auxiliar Sample Size_original\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7e73f02b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Particle Length imputado correctamente\n",
      "Missing tras imputación: 0\n"
     ]
    }
   ],
   "source": [
    "# Normalizar Shape (quitar espacios, convertir \"Not Reported\" a NA)\n",
    "df2['Shape'] = df2['Shape'].astype(str).str.strip()\n",
    "df2['Shape'] = df2['Shape'].replace({'Not Reported': np.nan})\n",
    "\n",
    "# Flag de missing\n",
    "df2['particle_length_missing'] = df2['Particle Length (μm)'].isna().astype(int)\n",
    "\n",
    "# Cálculo de medianas\n",
    "median_global = df2['Particle Length (μm)'].median()\n",
    "median_by_shape = df2.groupby('Shape')['Particle Length (μm)'].median()\n",
    "\n",
    "# Función de imputación\n",
    "def impute_particle_length(row):\n",
    "    if pd.notna(row['Particle Length (μm)']):\n",
    "        return row['Particle Length (μm)']\n",
    "    shape = row['Shape']\n",
    "    if pd.notna(shape) and pd.notna(median_by_shape.get(shape, np.nan)):\n",
    "        return median_by_shape[shape]\n",
    "    return median_global\n",
    "\n",
    "# Aplicación\n",
    "df2['Particle Length (μm)'] = df2.apply(impute_particle_length, axis=1)\n",
    "\n",
    "print(\"✔ Particle Length imputado correctamente\")\n",
    "print(\"Missing tras imputación:\", df2['Particle Length (μm)'].isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e11c0e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Shape imputado como 'unknown'\n",
      "['Sphere', 'Fragment', 'Fiber', 'unknown']\n",
      "Categories (4, object): ['Fiber', 'Fragment', 'Sphere', 'unknown']\n"
     ]
    }
   ],
   "source": [
    "# Crear flag de missing\n",
    "df2[\"shape_missing\"] = df2[\"Shape\"].isna().astype(int)\n",
    "\n",
    "# Imputar como categoría 'unknown'\n",
    "df2[\"Shape\"] = df2[\"Shape\"].fillna(\"unknown\")\n",
    "\n",
    "# Convertir a categoría\n",
    "df2[\"Shape\"] = df2[\"Shape\"].astype(\"category\")\n",
    "\n",
    "print(\"✔ Shape imputado como 'unknown'\")\n",
    "print(df2[\"Shape\"].unique()[:20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b82540e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Density (g/cm^3) imputado correctamente\n",
      "Mediana global usada: 1.07\n",
      "Missing tras imputación: 0\n"
     ]
    }
   ],
   "source": [
    "# Density (g/cm^3) — imputación por mediana global\n",
    "\n",
    "col = \"Density (g/cm^3)\"\n",
    "\n",
    "# Forzar numérico por seguridad\n",
    "df2[col] = pd.to_numeric(df2[col], errors=\"coerce\")\n",
    "\n",
    "# Crear flag de missing\n",
    "df2[\"density_missing\"] = df2[col].isna().astype(int)\n",
    "\n",
    "# Mediana global\n",
    "density_median = df2[col].median()\n",
    "\n",
    "# Imputación\n",
    "df2[col] = df2[col].fillna(density_median)\n",
    "\n",
    "print(\"✔ Density (g/cm^3) imputado correctamente\")\n",
    "print(\"Mediana global usada:\", density_median)\n",
    "print(\"Missing tras imputación:\", df2[col].isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "32208b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Dosing Frequency imputado correctamente\n",
      "Mediana usada: 1.0\n",
      "Missing tras imputación: 0\n"
     ]
    }
   ],
   "source": [
    "col = \"Dosing Frequency\"\n",
    "\n",
    "# Forzar a numérico\n",
    "df2[col] = pd.to_numeric(df2[col], errors=\"coerce\")\n",
    "\n",
    "# Crear flag missing\n",
    "df2[\"dosing_frequency_missing\"] = df2[col].isna().astype(int)\n",
    "\n",
    "# Calcular mediana global\n",
    "median_dosing = df2[col].median()\n",
    "\n",
    "# Imputar\n",
    "df2[col] = df2[col].fillna(median_dosing)\n",
    "\n",
    "print(\"✔ Dosing Frequency imputado correctamente\")\n",
    "print(\"Mediana usada:\", median_dosing)\n",
    "print(\"Missing tras imputación:\", df2[col].isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6405b220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Size Validated? imputado y normalizado correctamente\n",
      "Size Validated?\n",
      "yes        6523\n",
      "no         5512\n",
      "unknown     230\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "col = \"Size Validated?\"\n",
    "\n",
    "# Normalizar strings\n",
    "df2[col] = df2[col].astype(str).str.strip().str.lower()\n",
    "\n",
    "# Convertir variaciones a sí/no\n",
    "df2[col] = df2[col].replace({\n",
    "    \"y\": \"yes\",\n",
    "    \"yes\": \"yes\",\n",
    "    \"n\": \"no\",\n",
    "    \"no\": \"no\",\n",
    "    \"nan\": np.nan\n",
    "})\n",
    "\n",
    "# Crear flag de missing original\n",
    "df2[\"size_validated_missing\"] = df2[col].isna().astype(int)\n",
    "\n",
    "# Imputar NA como 'unknown'\n",
    "df2[col] = df2[col].fillna(\"unknown\")\n",
    "\n",
    "# Crear flags dummy\n",
    "df2[\"size_validated_yes\"] = (df2[col] == \"yes\").astype(int)\n",
    "df2[\"size_validated_no\"] = (df2[col] == \"no\").astype(int)\n",
    "df2[\"size_validated_unknown\"] = (df2[col] == \"unknown\").astype(int)\n",
    "\n",
    "print(\"✔ Size Validated? imputado y normalizado correctamente\")\n",
    "print(df2[col].value_counts(dropna=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fb2f362b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Shape Validated imputado y normalizado correctamente\n",
      "Shape Validated\n",
      "yes        6511\n",
      "no         5524\n",
      "unknown     230\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "col = \"Shape Validated\"\n",
    "\n",
    "# Normalizar strings\n",
    "df2[col] = df2[col].astype(str).str.strip().str.lower()\n",
    "\n",
    "# Convertir variaciones a sí/no\n",
    "df2[col] = df2[col].replace({\n",
    "    \"y\": \"yes\",\n",
    "    \"yes\": \"yes\",\n",
    "    \"n\": \"no\",\n",
    "    \"no\": \"no\",\n",
    "    \"nan\": np.nan\n",
    "})\n",
    "\n",
    "# Flag original de missing\n",
    "df2[\"shape_validated_missing\"] = df2[col].isna().astype(int)\n",
    "\n",
    "# Imputación → unknown\n",
    "df2[col] = df2[col].fillna(\"unknown\")\n",
    "\n",
    "# Crear dummies\n",
    "df2[\"shape_validated_yes\"] = (df2[col] == \"yes\").astype(int)\n",
    "df2[\"shape_validated_no\"] = (df2[col] == \"no\").astype(int)\n",
    "df2[\"shape_validated_unknown\"] = (df2[col] == \"unknown\").astype(int)\n",
    "\n",
    "print(\"✔ Shape Validated imputado y normalizado correctamente\")\n",
    "print(df2[col].value_counts(dropna=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9963e727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Effect imputado correctamente\n",
      "Effect\n",
      "no         8011\n",
      "yes        4104\n",
      "unknown     150\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "col = \"Effect\"\n",
    "\n",
    "# normalizar strings\n",
    "df2[col] = df2[col].astype(str).str.strip().str.lower()\n",
    "df2[col] = df2[col].replace({\"nan\": np.nan})\n",
    "\n",
    "# flag original de missing\n",
    "df2[\"effect_missing\"] = df2[col].isna().astype(int)\n",
    "\n",
    "# imputación\n",
    "df2[col] = df2[col].fillna(\"unknown\")\n",
    "\n",
    "# dummies opcionales\n",
    "df2[\"effect_yes\"] = (df2[col] == \"yes\").astype(int)\n",
    "df2[\"effect_no\"] = (df2[col] == \"no\").astype(int)\n",
    "df2[\"effect_unknown\"] = (df2[col] == \"unknown\").astype(int)\n",
    "\n",
    "print(\"✔ Effect imputado correctamente\")\n",
    "print(df2[col].value_counts(dropna=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "569d7fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Uptake Validated? imputado correctamente\n",
      "Uptake Validated?\n",
      "yes        6755\n",
      "no         5415\n",
      "unknown      95\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "col = \"Uptake Validated?\"\n",
    "\n",
    "# Normalizar strings\n",
    "df2[col] = df2[col].astype(str).str.strip().str.lower()\n",
    "df2[col] = df2[col].replace({\n",
    "    \"yes\": \"yes\",\n",
    "    \"y\": \"yes\",\n",
    "    \"no\": \"no\",\n",
    "    \"n\": \"no\",\n",
    "    \"nan\": np.nan\n",
    "})\n",
    "\n",
    "# Flag original de missing\n",
    "df2[\"uptake_validated_missing\"] = df2[col].isna().astype(int)\n",
    "\n",
    "# Imputación\n",
    "df2[col] = df2[col].fillna(\"unknown\")\n",
    "\n",
    "# Dummies opcionales\n",
    "df2[\"uptake_yes\"] = (df2[col] == \"yes\").astype(int)\n",
    "df2[\"uptake_no\"] = (df2[col] == \"no\").astype(int)\n",
    "df2[\"uptake_unknown\"] = (df2[col] == \"unknown\").astype(int)\n",
    "\n",
    "print(\"✔ Uptake Validated? imputado correctamente\")\n",
    "print(df2[col].value_counts(dropna=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "506f8611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Species imputado correctamente\n",
      "Species\n",
      "Danio rerio                  1990\n",
      "Oryzias melastigma           1022\n",
      "Daphnia magna                 580\n",
      "Oncorhynchus mykiss           560\n",
      "Mytilus galloprovincialis     463\n",
      "Name: count, dtype: int64\n",
      "NAs tras imputación: 0\n"
     ]
    }
   ],
   "source": [
    "col = \"Species\"\n",
    "\n",
    "# Normalizar\n",
    "df2[col] = df2[col].astype(str).str.strip()\n",
    "df2[col] = df2[col].replace({\"nan\": np.nan, \"NA NA\": np.nan})\n",
    "\n",
    "# Flag original de nulos\n",
    "df2[\"species_missing\"] = df2[col].isna().astype(int)\n",
    "\n",
    "# Imputación simple\n",
    "df2[col] = df2[col].fillna(\"unknown_species\")\n",
    "\n",
    "print(\"✔ Species imputado correctamente\")\n",
    "print(df2[col].value_counts().head())\n",
    "print(\"NAs tras imputación:\", df2[col].isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5758481e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Concentration Validated? imputado correctamente\n",
      "Concentration Validated?\n",
      "no         8917\n",
      "yes        3304\n",
      "unknown      44\n",
      "Name: count, dtype: int64\n",
      "NAs tras imputación: 0\n"
     ]
    }
   ],
   "source": [
    "col = \"Concentration Validated?\"\n",
    "\n",
    "# Normalizar\n",
    "df2[col] = df2[col].astype(str).str.strip().str.lower()\n",
    "df2[col] = df2[col].replace({\n",
    "    \"y\": \"yes\", \"n\": \"no\",\n",
    "    \"yes\": \"yes\", \"no\": \"no\",\n",
    "    \"nan\": np.nan\n",
    "})\n",
    "\n",
    "# Flag original de NA\n",
    "df2[\"concentration_validated_missing\"] = df2[col].isna().astype(int)\n",
    "\n",
    "# Imputación con unknown\n",
    "df2[col] = df2[col].fillna(\"unknown\")\n",
    "\n",
    "print(\"✔ Concentration Validated? imputado correctamente\")\n",
    "print(df2[col].value_counts(dropna=False))\n",
    "print(\"NAs tras imputación:\", df2[col].isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f2ef5eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Exposure Duration imputado correctamente\n",
      "Mediana global usada: 14.0\n",
      "NAs tras imputación: 0\n"
     ]
    }
   ],
   "source": [
    "col = \"Exposure Duration (days)\"\n",
    "\n",
    "# Convertir a numérico\n",
    "df2[col] = pd.to_numeric(df2[col], errors=\"coerce\")\n",
    "\n",
    "# Flag original de missing\n",
    "df2[\"exposure_duration_missing\"] = df2[col].isna().astype(int)\n",
    "\n",
    "# Mediana global\n",
    "median_global = df2[col].median()\n",
    "\n",
    "# Imputación\n",
    "df2[col] = df2[col].fillna(median_global)\n",
    "\n",
    "print(\"✔ Exposure Duration imputado correctamente\")\n",
    "print(\"Mediana global usada:\", median_global)\n",
    "print(\"NAs tras imputación:\", df2[col].isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "420764b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Size Category imputado con 'unknown'\n",
      "Valores finales: ['1µm < 100µm', '100µm < 1mm', '1nm < 100nm', '100nm < 1µm', '1mm < 5mm', 'unknown']\n",
      "Categories (6, object): ['100nm < 1µm', '100µm < 1mm', '1mm < 5mm', '1nm < 100nm', '1µm < 100µm', 'unknown']\n"
     ]
    }
   ],
   "source": [
    "col = \"Size Category\"\n",
    "\n",
    "# Normalizar texto\n",
    "df2[col] = df2[col].astype(str).str.strip()\n",
    "\n",
    "# Convertir \"Not Reported\" → NaN\n",
    "df2[col] = df2[col].replace({\"Not Reported\": np.nan, \"nan\": np.nan})\n",
    "\n",
    "# Flag original de missing\n",
    "df2[\"size_category_missing\"] = df2[col].isna().astype(int)\n",
    "\n",
    "# Imputación con categoría explícita\n",
    "df2[col] = df2[col].fillna(\"unknown\")\n",
    "\n",
    "# Convertir a categoría\n",
    "df2[col] = df2[col].astype(\"category\")\n",
    "\n",
    "print(\"✔ Size Category imputado con 'unknown'\")\n",
    "print(\"Valores finales:\", df2[col].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e994b67c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Replicates imputado correctamente\n",
      "Moda global usada: 3.0\n",
      "Valores finales únicos: <IntegerArray>\n",
      "[ 8,  3,  6,  4, 12, 15,  5,  1,  2, 20, 10,  7,  9, 13, 24, 11, 45, 16, 14,\n",
      " 17, 36, 33, 40, 30, 18, 27,  0]\n",
      "Length: 27, dtype: Int64\n"
     ]
    }
   ],
   "source": [
    "col = \"Replicates\"\n",
    "\n",
    "# Convertir a string y limpiar\n",
    "df2[col] = df2[col].astype(str).str.strip().replace({\"nan\": np.nan})\n",
    "\n",
    "# Función para extraer primer número \n",
    "def extract_first_number(x):\n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    s = str(x)\n",
    "    m = re.search(r\"[-+]?\\d*\\.?\\d+\", s)\n",
    "    if m:\n",
    "        try:\n",
    "            return float(m.group(0))\n",
    "        except:\n",
    "            return np.nan\n",
    "    return np.nan\n",
    "\n",
    "# Extraer número limpio\n",
    "df2[col] = df2[col].apply(extract_first_number)\n",
    "\n",
    "# Flag opcional para trazabilidad\n",
    "df2[\"replicates_missing\"] = df2[col].isna().astype(int)\n",
    "\n",
    "# Imputación: moda global\n",
    "mode_value = df2[col].mode()[0]\n",
    "df2[col] = df2[col].fillna(mode_value)\n",
    "\n",
    "# Convertir a entero si todos los valores lo permiten\n",
    "if df2[col].dropna().apply(float.is_integer).all():\n",
    "    df2[col] = df2[col].astype(\"Int64\")\n",
    "\n",
    "print(\"✔ Replicates imputado correctamente\")\n",
    "print(\"Moda global usada:\", mode_value)\n",
    "print(\"Valores finales únicos:\", df2[col].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c9f57df6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "particles/mL water (master)               32.026091\n",
       "μg/mL water (master)                      25.894823\n",
       "Authors                                    0.000000\n",
       "Year                                       0.000000\n",
       "Source                                     0.000000\n",
       "DOI                                        0.000000\n",
       "Species                                    0.000000\n",
       "Organism Group                             0.000000\n",
       "Environment                                0.000000\n",
       "Life Stage                                 0.000000\n",
       "In vitro/in vivo                           0.000000\n",
       "Sex                                        0.000000\n",
       "Estimated Body Length (cm)                 0.000000\n",
       "Estimated Maximum Ingestible Size (mm)     0.000000\n",
       "Experiment Type                            0.000000\n",
       "Exposure Route                             0.000000\n",
       "Particle Mix?                              0.000000\n",
       "Negative Control                           0.000000\n",
       "Reference Particle                         0.000000\n",
       "Exposure Media                             0.000000\n",
       "Technical \"Red Criteria\"                   0.000000\n",
       "Risk Assessment \"Red Criteria\"             0.000000\n",
       "Detergent                                  0.000000\n",
       "Solvent                                    0.000000\n",
       "Temperature (Avg)                          0.000000\n",
       "Exposure Duration (days)                   0.000000\n",
       "Replicates                                 0.000000\n",
       "Sample Size                                0.000000\n",
       "Acute/Chronic                              0.000000\n",
       "Number of Doses                            0.000000\n",
       "Chemicals Added                            0.000000\n",
       "Dosing Frequency                           0.000000\n",
       "Added Chemical Dose (mg/L, nominal)        0.000000\n",
       "Effect                                     0.000000\n",
       "Direction                                  0.000000\n",
       "Broad Endpoint Category                    0.000000\n",
       "Specific Endpoint Category                 0.000000\n",
       "Endpoint                                   0.000000\n",
       "Level of Biological Organization           0.000000\n",
       "Target Cell or Tissue                      0.000000\n",
       "Effect Metric                              0.000000\n",
       "AF Time                                    0.000000\n",
       "AF NOEC                                    0.000000\n",
       "Polymer                                    0.000000\n",
       "Shape                                      0.000000\n",
       "Density (g/cm^3)                           0.000000\n",
       "Density, reported or estimated             0.000000\n",
       "Charge                                     0.000000\n",
       "Zeta Potential (mV)                        0.000000\n",
       "Zeta Potential Media                       0.000000\n",
       "Particle Length (μm)                       0.000000\n",
       "Particle Width (μm)                        0.000000\n",
       "Size Category                              0.000000\n",
       "Particle Surface Area (μm^2)               0.000000\n",
       "Particle Volume (μm^3)                     0.000000\n",
       "Particle Mass (mg)                         0.000000\n",
       "Weathered or Biofouled?                    0.000000\n",
       "Size Validated?                            0.000000\n",
       "Polymer Validated?                         0.000000\n",
       "Shape Validated                            0.000000\n",
       "Particle Source                            0.000000\n",
       "Sodium Azide Present?                      0.000000\n",
       "Screened for Chemical Contamination?       0.000000\n",
       "Particle Cleaning?                         0.000000\n",
       "Solvent Rinse                              0.000000\n",
       "Background Contamination Monitored?        0.000000\n",
       "Concentration Validated?                   0.000000\n",
       "Particle Behavior                          0.000000\n",
       "Uptake Validated?                          0.000000\n",
       "Organisms Fed?                             0.000000\n",
       "charge_missing                             0.000000\n",
       "zeta_media_missing                         0.000000\n",
       "zeta_missing                               0.000000\n",
       "zeta_imputed_by_group                      0.000000\n",
       "zeta_imputed_by_global                     0.000000\n",
       "effect_metric_missing                      0.000000\n",
       "af_noec_missing                            0.000000\n",
       "particle_width_missing                     0.000000\n",
       "particles_ml_missing                       0.000000\n",
       "ug_ml_water_missing                        0.000000\n",
       "estimated_body_length_missing              0.000000\n",
       "estimated_max_ingestible_missing           0.000000\n",
       "particle_mass_missing                      0.000000\n",
       "particle_mass_imputed_by_group             0.000000\n",
       "particle_mass_imputed_by_global            0.000000\n",
       "particle_volume_missing                    0.000000\n",
       "particle_area_missing                      0.000000\n",
       "density_reported_flag                      0.000000\n",
       "density_estimated_flag                     0.000000\n",
       "density_unknown_flag                       0.000000\n",
       "Sample Size_num                            0.000000\n",
       "sample_size_missing                        0.000000\n",
       "sample_size_outlier                        0.000000\n",
       "particle_length_missing                    0.000000\n",
       "shape_missing                              0.000000\n",
       "density_missing                            0.000000\n",
       "dosing_frequency_missing                   0.000000\n",
       "size_validated_missing                     0.000000\n",
       "size_validated_yes                         0.000000\n",
       "size_validated_no                          0.000000\n",
       "size_validated_unknown                     0.000000\n",
       "shape_validated_missing                    0.000000\n",
       "shape_validated_yes                        0.000000\n",
       "shape_validated_no                         0.000000\n",
       "shape_validated_unknown                    0.000000\n",
       "effect_missing                             0.000000\n",
       "effect_yes                                 0.000000\n",
       "effect_no                                  0.000000\n",
       "effect_unknown                             0.000000\n",
       "uptake_validated_missing                   0.000000\n",
       "uptake_yes                                 0.000000\n",
       "uptake_no                                  0.000000\n",
       "uptake_unknown                             0.000000\n",
       "species_missing                            0.000000\n",
       "concentration_validated_missing            0.000000\n",
       "exposure_duration_missing                  0.000000\n",
       "size_category_missing                      0.000000\n",
       "replicates_missing                         0.000000\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#nulos\n",
    "with pd.option_context('display.max_rows', None):\n",
    "    display(df2.isna().mean().sort_values(ascending=False) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "56c0e153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IntegerArray>\n",
       "[ 8,  3,  6,  4, 12, 15,  5,  1,  2, 20, 10,  7,  9, 13, 24, 11, 45, 16, 14,\n",
       " 17, 36, 33, 40, 30, 18, 27,  0]\n",
       "Length: 27, dtype: Int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['Replicates'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8bcffe40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_processed = df2\n",
    "df2_processed.to_csv(\"../data/processed/species_raw_processed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d0d31f1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12265, 118)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_processed.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
